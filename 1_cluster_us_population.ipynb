{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9fa3d6-659f-41ec-84a6-a4e0f74483fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483602c9-ee7e-41db-b699-f94f3d4c47f5",
   "metadata": {},
   "source": [
    "## H - Header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd1788-b7ae-4804-90f4-9cc6e1c7212f",
   "metadata": {},
   "source": [
    "#### H1 – libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c402192e-708e-4a74-a345-c7bfea14b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard foundational libraries\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "## import specific function\n",
    "from os              import mkdir, listdir\n",
    "from os.path         import isfile, isdir\n",
    "from datetime        import datetime, timedelta\n",
    "from dbfread         import DBF\n",
    "from geopy.distance  import geodesic\n",
    "from ipyparallel     import Cluster\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, OPTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e6bfc-e689-4615-9477-57587afc184a",
   "metadata": {},
   "source": [
    "#### H2 – basic automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f50357-a7fd-4ad3-9952-7de305854e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up standard directories if needed\n",
    "def make_standard_file_system():\n",
    "    for i in ['A_Input', 'B_Intermediate', 'C_Output']:\n",
    "        if not isdir(i): mkdir(i)\n",
    "\n",
    "## log time elapsed\n",
    "time_log = dict()\n",
    "def log_time(the_id = 'End Log'):\n",
    "    \n",
    "    ## construct new time stamp\n",
    "    now_time = str(datetime.now().hour).zfill(2)\n",
    "    now_time = now_time +':'+ str(datetime.now().minute).zfill(2)\n",
    "    now_time = now_time +':'+ str(datetime.now().second).zfill(2)\n",
    "\n",
    "    ## add to time log\n",
    "    if the_id == 'End Log':\n",
    "        time_log['End'] = now_time\n",
    "        print('Time log:')\n",
    "        for i in time_log.keys():\n",
    "            print(i.rjust(5) + ':', time_log[i])\n",
    "    else:\n",
    "        time_log[the_id] = now_time\n",
    "        \n",
    "## toggle cache versus build\n",
    "def build_or_cache(function, address, permit):\n",
    "    if permit and isfile(address):\n",
    "        print('Build/Cache Decision: Cache')\n",
    "        the_file = pd.read_csv(address, index_col = 0)\n",
    "    else:\n",
    "        print('Build/Cache Decision: Build')\n",
    "        the_file = function()\n",
    "    return the_file\n",
    "    \n",
    "## execute functions\n",
    "make_standard_file_system()\n",
    "log_time('H2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa200f04-560d-41a2-aa39-32cde6a5fcdd",
   "metadata": {},
   "source": [
    "#### H3 – settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a810ea4-69f8-446d-ae9b-fae82f7a0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## server mode (switches off data sampling; full distance data too big for a PC)\n",
    "server_mode = False\n",
    "\n",
    "## GD settings\n",
    "set_gd = dict()\n",
    "\n",
    "## RD settings\n",
    "set_rd = {'1_cache': True}\n",
    "\n",
    "## MD settings\n",
    "set_md = {'1_cache': True, '2_cache': True}\n",
    "\n",
    "## EMR settings\n",
    "set_emr = dict()\n",
    "\n",
    "## PVD settings\n",
    "set_pvd = dict()\n",
    "\n",
    "## RV settings\n",
    "set_rv = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996ca5b-6afa-4efd-beec-4478c9896c4c",
   "metadata": {},
   "source": [
    "## GD - Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373c0c5-10b3-4028-95c4-ed57b16fdff3",
   "metadata": {},
   "source": [
    "Primary data source:\n",
    "+ 2020 TIGER shapefiles from the US Census (the .dbf files)\n",
    "+ 2020 DP series population summary tables from US Census (as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2efc95-73d7-4ea5-a4bf-4c531d8dc57b",
   "metadata": {},
   "source": [
    "#### GD1 - read in primary data (census tract shapefile .dbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9897df-5ebb-46bd-a49e-98718c379f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## read in dbf files for census tracts\n",
    "def read_tract_dbf(directory):\n",
    "    \n",
    "    ## file dbf files in target directory\n",
    "    dbf_addr = listdir(directory)\n",
    "    dbf_addr = [i for i in dbf_addr if i[-3::] == 'dbf']\n",
    "    \n",
    "    ## read relevant columns from each\n",
    "    desired_columns = {'GEOID': str,\n",
    "                       'STATEFP': str, 'COUNTYFP':str, 'TRACTCE':str,\n",
    "                        'INTPTLAT': float, 'INTPTLON': float, 'ALAND': int}\n",
    "    dbf_data = []\n",
    "    for i in dbf_addr:\n",
    "        i_dbf = pd.DataFrame(iter(DBF(directory + '/' + i)))\n",
    "        i_dbf = i_dbf[desired_columns.keys()].astype(desired_columns)\n",
    "        dbf_data.append(i_dbf)\n",
    "        \n",
    "    ## compile data into a single file and export\n",
    "    dbf_data = pd.concat(dbf_data, axis = 0).sort_values('GEOID')\n",
    "    dbf_data['count'] = 1\n",
    "    dbf_data = dbf_data.reset_index(drop = True)\n",
    "    dbf_data.to_csv('B_Intermediate/dbf_data.csv.gz')\n",
    "    return dbf_data\n",
    "    \n",
    "## execute code\n",
    "dbf_data = read_tract_dbf('A_Input/tracts_dbf')\n",
    "if not server_mode: # 04 = AZ, 08 = CO, NM = 35, UT = 49\n",
    "    dbf_data = dbf_data.loc[dbf_data.STATEFP.isin(['49', '08', '04', '35'])]\n",
    "log_time('GD1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca96540-be5a-4a32-b864-e943df7b9fec",
   "metadata": {},
   "source": [
    "#### GD2 - Read in secondary data (census DP table columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201aacb-a203-42ba-a23a-dd759d3dbd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c59b35fe-09d5-449c-80f7-b9cf0b0cfc37",
   "metadata": {},
   "source": [
    "## RD - Refine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bba94a-9f9a-496d-b8b2-454bcad0619d",
   "metadata": {},
   "source": [
    "#### RD1 – calculate and cache geographic distances between tract centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a9c611-546b-4d5c-b717-3f6c54cd656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build/Cache Decision: Cache\n"
     ]
    }
   ],
   "source": [
    "## reshape tract coordinate data to input format\n",
    "tract_xy = list(zip(dbf_data.INTPTLAT.values, dbf_data.INTPTLON.values))\n",
    "\n",
    "## define function to do distance compuations in parallel\n",
    "def measure_distance_in_parallel(xy = tract_xy):\n",
    "    the_iter = list(range(0, len(xy)))\n",
    "    \n",
    "    ## define engine function that will run on each parallel process\n",
    "    def measure_distance_parallel_slice(n, xy_col = xy):\n",
    "        from geopy.distance import geodesic\n",
    "        xy_col = xy_col.copy()\n",
    "        xy_row = xy_col[n]\n",
    "        xy_dist = []\n",
    "        for i in xy_col[0:n]: xy_dist.append(0)\n",
    "        for i in xy_col[n::]:\n",
    "            xy_dist.append(int(round(geodesic(xy_row, i).miles)))\n",
    "        return xy_dist\n",
    "\n",
    "    ## run engine in parallel for each slice of the data\n",
    "    with Cluster(n = 4) as clust:\n",
    "        view = clust.load_balanced_view()\n",
    "        asyncresult = view.map_async(measure_distance_parallel_slice, the_iter)\n",
    "        asyncresult.wait_interactive()\n",
    "        result = asyncresult.get()\n",
    "        \n",
    "    ## package results and export\n",
    "    result = np.array(result)\n",
    "    result = result + result.T\n",
    "    result = pd.DataFrame(result)\n",
    "    result.to_csv('B_Intermediate/tract_distance.csv.gz')\n",
    "    return result\n",
    "\n",
    "tract_distance = build_or_cache(\n",
    "    function = measure_distance_in_parallel,\n",
    "    address = 'B_Intermediate/tract_distance.csv.gz',\n",
    "    permit = set_rd['1_cache']\n",
    "    )\n",
    "\n",
    "log_time('RD1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601721c-6ac0-4206-8b41-7dc0f99ba12a",
   "metadata": {},
   "source": [
    "#### RD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd121a39-e3dd-4dca-a014-6b67d5a1b2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab2bc34c-768b-456c-9c94-ec44196844c8",
   "metadata": {},
   "source": [
    "## MD - Model Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e4eb3-1b81-4b8f-9700-13e04174d097",
   "metadata": {},
   "source": [
    "#### MD0 - build common components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06aa2b3b-cc94-447f-91c0-99ba2dfe6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## score model\n",
    "def score_model(clusters, d):\n",
    "    score = clusters * np.ones(d.shape)\n",
    "    mask = (score != -1) & (score.T != -1)\n",
    "    score = (score == score.T) * mask * np.array(d)\n",
    "    the_denom = np.sum(d.sum().values)\n",
    "    return np.round(np.sum(score) / the_denom, 3)\n",
    "\n",
    "## run model across different parameters\n",
    "model_name = 'EMPTY'\n",
    "model_list = dict()\n",
    "def run_model(dist = tract_distance):\n",
    "    \n",
    "    ##  retrieve objects from external environment\n",
    "    model_dict = model_list\n",
    "    addr_name = model_name\n",
    "    \n",
    "    ## declare container objects for model results\n",
    "    model_clusters = dict()\n",
    "    model_stats    = dict()\n",
    "    \n",
    "    ## fit model and populate container objects with model performance data\n",
    "    for i in model_dict.keys():\n",
    "        model_clusters[i] = model_dict[i].fit_predict(dist)\n",
    "        model_stats[i] = dict()\n",
    "        model_stats[i]['name'] = i\n",
    "        model_stats[i]['score'] = score_model(model_clusters[i], d = dist)\n",
    "        model_stats[i]['clusters'] = len(set(model_clusters[i]))\n",
    "        model_stats[i]['outliers'] = sum(model_clusters[i] == -1)\n",
    "        \n",
    "    ## package results and export\n",
    "    model_clusters = pd.DataFrame(model_clusters)\n",
    "    model_clusters.to_csv('B_Intermediate/Model_' + addr_name + '_Clust.csv.gz')\n",
    "    model_stats = pd.DataFrame(model_stats).T\n",
    "    model_stats = model_stats.astype({'clusters':int, 'outliers':int})\n",
    "    model_stats.to_csv('B_Intermediate/Model_' + addr_name + '_Stats.csv')\n",
    "    return model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53422e30-1a5d-4e66-8f4a-431413efad83",
   "metadata": {},
   "source": [
    "#### MD1 and MD2 - run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd5cd65-9122-4230-be26-e594d798ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build/Cache Decision: Build\n",
      "Build/Cache Decision: Build\n"
     ]
    }
   ],
   "source": [
    "## -- cluster population by agglomeration\n",
    "\n",
    "## assemble models\n",
    "model_agglomeration = dict()\n",
    "for i in range(250 - 150, 250 + 150, 10):\n",
    "    model_iter = AgglomerativeClustering(\n",
    "        n_clusters = None, compute_full_tree = True,\n",
    "        affinity = 'precomputed', linkage = 'average',\n",
    "        distance_threshold = i)\n",
    "    model_agglomeration[str(int(i))] = model_iter\n",
    "    \n",
    "## execute models\n",
    "model_name = 'Agglomeration'\n",
    "model_list = model_agglomeration\n",
    "agglomeration_score = build_or_cache(\n",
    "    function = run_model,\n",
    "    address = 'B_Intermediate/Model_' + model_name + '_Stats.csv',\n",
    "    permit = set_md['1_cache']\n",
    "    )\n",
    "\n",
    "log_time('MD1')\n",
    "\n",
    "## -- cluster population by DBSCAN\n",
    "\n",
    "## assemble models\n",
    "model_dbscan = dict()\n",
    "for i in range(25 - 15, 25 + 15, 1):\n",
    "    model_iter = DBSCAN(eps = i, metric = 'precomputed', n_jobs = 8)\n",
    "    model_dbscan[str(int(i))] = model_iter\n",
    "    \n",
    "## execute models\n",
    "model_name = 'DBSCAN'\n",
    "model_list = model_dbscan\n",
    "agglomeration_score = build_or_cache(\n",
    "    function = run_model,\n",
    "    address = 'B_Intermediate/Model_' + model_name + '_Stats.csv',\n",
    "    permit = set_md['2_cache']\n",
    "    )\n",
    "\n",
    "log_time('MD2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e0f57-ddfc-4750-9ee9-6382bbe031c0",
   "metadata": {},
   "source": [
    "## EMR - Enrich Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0976d-dd00-411a-9c77-e23dd233f27a",
   "metadata": {},
   "source": [
    "#### EMR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f445de-fefb-4f4b-ac9a-560c2ea12125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac38a6b2-bd67-4cfd-b3ef-45d87ec20fc0",
   "metadata": {},
   "source": [
    "#### EMR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13daaba1-484d-449b-ba13-532d98ad4c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374809b7-53b4-4720-a8e4-b4ba395dc53a",
   "metadata": {},
   "source": [
    "## PVD - Prepare Visualization Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203acbe7-9577-4582-9299-91c5099c3392",
   "metadata": {},
   "source": [
    "#### PVD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4066a-99d3-4c41-92e7-6e80adeadae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a2b35e9-de29-401c-b6d4-b872bcf3a693",
   "metadata": {},
   "source": [
    "#### PVD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8fe1a-1aa5-4a58-a091-22a4df3cac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d44eb901-c053-40db-b9c4-29229d60fa18",
   "metadata": {},
   "source": [
    "## RV - Render Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba65c4-114f-469d-83a9-73ded9e63547",
   "metadata": {},
   "source": [
    "#### RV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03653764-eb82-4dee-9089-4922e9003ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aadfe998-02dd-40b3-aa14-fb3f19ffd791",
   "metadata": {},
   "source": [
    "#### RV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291e682-93f1-46a9-8712-597f5faccaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5115a9-7210-4bcc-a7f5-b3ba8dce55e2",
   "metadata": {},
   "source": [
    "## F - Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191b03-9043-4e5b-85d2-f97aa357a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db352693-855a-402d-af68-6a1d8639a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time log:\n",
      "   H2: 14:14:21\n",
      "  GD1: 14:14:24\n",
      "  RD1: 14:14:26\n",
      "  MD1: 14:15:00\n",
      "  MD2: 14:15:37\n",
      "  End: 14:15:37\n"
     ]
    }
   ],
   "source": [
    "log_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b249d53-d193-4008-9975-a451284ee066",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########==========##########==========##########==========##########=========="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
