{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84ff307-1f5b-4341-9bd9-90d82b9a60b1",
   "metadata": {},
   "source": [
    "# H - Header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fd9fc-433c-48fe-a986-f74fb1c692e4",
   "metadata": {},
   "source": [
    "#### H1 - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2893cbc5-099e-469b-88d6-3481d734115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard foundational libraries\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## import specific functions\n",
    "from os                 import mkdir, listdir\n",
    "from os.path            import isfile, isdir\n",
    "from datetime           import datetime, timedelta\n",
    "from cartopy            import feature\n",
    "from cartopy.crs        import LambertConformal, PlateCarree\n",
    "from dbfread            import DBF\n",
    "from docx               import Document\n",
    "from textwrap           import fill as txt_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46a131-c865-43fc-80be-1c2c1576466f",
   "metadata": {},
   "source": [
    "#### H2 - Basic Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e061a3d-8cb6-4bd5-8f67-881c337b1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up standard directories if needed\n",
    "def make_standard_file_system():\n",
    "    for i in ['A_Input', 'B_Intermediate', 'C_Output']:\n",
    "        if not isdir(i): mkdir(i)\n",
    "\n",
    "## log time elapsed\n",
    "time_log = dict()\n",
    "def log_time(the_id = 'End Log'):\n",
    "    \n",
    "    ## construct new time stamp\n",
    "    now_time = str(datetime.now().hour).zfill(2)\n",
    "    now_time = now_time +':'+ str(datetime.now().minute).zfill(2)\n",
    "    now_time = now_time +':'+ str(datetime.now().second).zfill(2)\n",
    "\n",
    "    ## add to time log\n",
    "    if the_id == 'End Log':\n",
    "        time_log['End'] = now_time\n",
    "        print('Time log:')\n",
    "        for i in time_log.keys():\n",
    "            print(i.rjust(5) + ':', time_log[i])\n",
    "    else:\n",
    "        time_log[the_id] = now_time\n",
    "        \n",
    "## toggle cache versus build\n",
    "def build_or_cache(function, address, permit):\n",
    "    if permit and isfile(address):\n",
    "        print('Build/Cache Decision: Cache')\n",
    "        the_file = pd.read_csv(address, index_col = 0)\n",
    "    else:\n",
    "        print('Build/Cache Decision: Build')\n",
    "        the_file = function()\n",
    "    return the_file\n",
    "    \n",
    "## execute functions\n",
    "make_standard_file_system()\n",
    "log_time('H2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12f165-5257-40f4-b625-5950dac2d955",
   "metadata": {},
   "source": [
    "#### H3 - Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9577a3a0-6eb6-4a48-a510-a8d779269232",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set color palette\n",
    "set_color = {\n",
    "    'AzureDark'    :(7/12, 1.0, 0.4),\n",
    "    'AzureMedium'  :(7/12, 0.7, 0.7),\n",
    "    'AzureLight'   :(7/12, 0.4, 1.0),\n",
    "    'AzureBG'      :(7/12, 0.1, 1.0),\n",
    "    'AzureOverlay' :(7/12, 0.1, 1.0, 0.5),\n",
    "    \n",
    "    'OrangeDark'   :(1/12, 1.0, 0.4),\n",
    "    'OrangeMedium' :(1/12, 0.7, 0.7),\n",
    "    'OrangeLight'  :(1/12, 0.4, 1.0),\n",
    "    'OrangeBG'     :(1/12, 0.1, 1.0),\n",
    "    'OrangeOverlay':(1/12, 0.1, 1.0, 0.5) \n",
    "    }\n",
    "\n",
    "## set font sizes\n",
    "set_font = {\n",
    "    'small' : 16,\n",
    "    'medium': 24,\n",
    "    'large' : 32\n",
    "    }\n",
    "\n",
    "## time-saver settings\n",
    "set_acceleration = {\n",
    "    'dbf_cache':True,\n",
    "    'sample_size':1/20,\n",
    "    'distance_cache':False,\n",
    "    'cluster_cache':False\n",
    "    }\n",
    "\n",
    "## map parameters\n",
    "set_map = {\n",
    "    'bounds'  : [-124.73 + 5, -66.95 - 5, 25.12 - 3.3, 49.38 + 3.3],\n",
    "    'map_proj': LambertConformal(\n",
    "        central_longitude = (-124.73 - 66.95) / 2,\n",
    "        central_latitude = (25.12 + 49.38) / 2,\n",
    "        standard_parallels = (25.12, 49.38)\n",
    "        )\n",
    "    }\n",
    "\n",
    "log_time('H3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255532f-66e3-45f4-b62c-aaf8f2941744",
   "metadata": {},
   "source": [
    "# GD - Gather Data / RD - Refine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149febf-9577-46d1-80f9-aa0a37dad8f9",
   "metadata": {},
   "source": [
    "#### GD1 - read census tract geographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b030f7-3b12-41e6-9dc5-1fe7eabbf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build/Cache Decision: Cache\n"
     ]
    }
   ],
   "source": [
    "def read_geo_data(directory = 'A_Input/tracts_dbf'):\n",
    "    \n",
    "    ## list dbf files in target directory\n",
    "    dbf_addr = listdir(directory)\n",
    "    dbf_addr = [i for i in dbf_addr if i[-3::] == 'dbf']\n",
    "    \n",
    "    ## define relevant columns from each\n",
    "    desired_columns = {'GEOID': str,\n",
    "                       'STATEFP': str, 'COUNTYFP':str, 'TRACTCE':str,\n",
    "                        'INTPTLAT': float, 'INTPTLON': float, 'ALAND': int}\n",
    "    \n",
    "    ## read in all dbf files\n",
    "    dbf_data = []\n",
    "    for i in dbf_addr:\n",
    "        i_dbf = pd.DataFrame(iter(DBF(directory + '/' + i)))\n",
    "        i_dbf = i_dbf[desired_columns.keys()].astype(desired_columns)\n",
    "        dbf_data.append(i_dbf)\n",
    "        \n",
    "    ## compile data into a single file\n",
    "    dbf_data = pd.concat(dbf_data, axis = 0).sort_values('GEOID')\n",
    "    dbf_data['count'] = 1\n",
    "    dbf_data = dbf_data.reset_index(drop = True)\n",
    "    \n",
    "    ## export data\n",
    "    dbf_data.to_csv('B_Intermediate/dbf_data.csv.gz')\n",
    "    return dbf_data\n",
    "\n",
    "## execute code\n",
    "geo_data = build_or_cache(function = read_geo_data,\n",
    "                          address = 'B_Intermediate/dbf_data.csv.gz',\n",
    "                          permit = set_acceleration['dbf_cache'])\n",
    "log_time('GD1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b44dd8-b3a4-4eff-a644-21bb455d388a",
   "metadata": {},
   "source": [
    "#### RD1 - draw a sample from the census tract geographic data and exclude outlier tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fd248c-6dab-40fe-83a5-2228ac349e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_geo_data(dat = geo_data, too_rural = 20.720e6 * 5,\n",
    "                    too_much = set_acceleration['sample_size']):\n",
    "    \n",
    "    ## filter out extremely rural areas (< 100 people per square mile)\n",
    "    dat = dat.loc[dat.ALAND < too_rural, :]\n",
    "    \n",
    "    ## take systematic sample of the data\n",
    "    i = np.arange(0, dat.shape[0]) % int(1 / too_much)\n",
    "    dat = dat.loc[i == 0, ]\n",
    "\n",
    "    ## return data\n",
    "    return dat\n",
    "\n",
    "## execute code\n",
    "geo_data = refine_geo_data()\n",
    "log_time('RD1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3373db0-4b46-4aac-8b01-9e6d8dfd92da",
   "metadata": {},
   "source": [
    "#### GD2 - read census population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28942f36-b9af-41e1-a844-c489d8d20c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pop_data(roster = 'A_Input/sources.csv'):\n",
    "    \n",
    "    ## read in data file roster\n",
    "    roster = pd.read_csv(roster).set_index('OBJ_NAME')\n",
    "    \n",
    "    ## load \n",
    "    pop_data = dict()\n",
    "    for i in roster.index:\n",
    "        var_names = roster.loc[i, 'VAR_NAME'].split(';')\n",
    "        pop_data[i] = pd.read_csv('A_Input' + '/' + roster.loc[i, 'FILE_NAME'],\n",
    "            usecols = var_names, dtype = str)\n",
    "\n",
    "    return pop_data\n",
    "\n",
    "## execute code\n",
    "pop_data = read_pop_data()\n",
    "log_time('GD2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd744f8f-2948-4bc1-b8f3-61a41011a660",
   "metadata": {},
   "source": [
    "#### RD2 - refine and compile census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba287d1-300b-42d3-a930-6865bcfab541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bc48382-fdbf-47c5-b7d1-0cbf51cc5691",
   "metadata": {},
   "source": [
    "#### GD3 / RD3 - read and refine text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a2da6a-4fc5-472a-b366-373019afd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_explanatory_text(addr = 'A_Input/explanation.docx', n = 47):\n",
    "    explain = Document(addr).paragraphs\n",
    "    explain = [txt_wrap(i.text, n) for i in explain]\n",
    "    explain = '\\n'.join(explain)\n",
    "    return explain\n",
    "\n",
    "## execute code\n",
    "explanatory_text = read_explanatory_text()\n",
    "log_time('RD3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58595a4-ffa6-407a-9fce-a86f9bfadef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time log:\n",
      "   H2: 13:34:44\n",
      "   H3: 13:34:44\n",
      "  GD1: 13:34:45\n",
      "  RD1: 13:34:45\n",
      "  GD2: 13:34:50\n",
      "  RD3: 13:34:50\n",
      "  End: 13:34:50\n"
     ]
    }
   ],
   "source": [
    "log_time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
